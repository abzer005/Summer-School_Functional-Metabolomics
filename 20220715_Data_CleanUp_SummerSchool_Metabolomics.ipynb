{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abzer005/Summer-School_Functional-Metabolomics/blob/main/20220715_Data_CleanUp_SummerSchool_Metabolomics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55766981",
      "metadata": {
        "id": "55766981"
      },
      "source": [
        "## Data Clean up\n",
        "Authors: Abzer Kelminal (abzer.shah@uni-tuebingen.de) <br>\n",
        "Edited by:  <br>\n",
        "Input file format: .csv files or .txt files <br>\n",
        "Outputs: .csv files  <br>\n",
        "Dependencies: ggplot2, dplyr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R Google Colab currently runs on the version ''4.2.0'. Hence, we are checking which R version we have:\n",
        "R.version.string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "tmcd8DuB1PRs",
        "outputId": "de860bd7-f4a7-4b02-ece8-bd38f10aeb1f"
      },
      "id": "tmcd8DuB1PRs",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'R version 4.2.0 (2022-04-22)'"
            ],
            "text/markdown": "'R version 4.2.0 (2022-04-22)'",
            "text/latex": "'R version 4.2.0 (2022-04-22)'",
            "text/plain": [
              "[1] \"R version 4.2.0 (2022-04-22)\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#installing and calling the necessary packages:\n",
        "if (!require(\"ggplot2\")) install.packages(\"ggplot2\")\n",
        "if (!require(\"dplyr\")) install.packages(\"dplyr\")"
      ],
      "metadata": {
        "id": "BvfG-ihq2PZP"
      },
      "id": "BvfG-ihq2PZP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Mounting Google Drive:"
      ],
      "metadata": {
        "id": "5MPbux1f2Qu0"
      },
      "id": "5MPbux1f2Qu0"
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages('googledrive') #only need to install occasionally\n",
        "install.packages('httpuv') \n",
        "library('googledrive') \n",
        "library('httpuv')"
      ],
      "metadata": {
        "id": "6A8MWDLyujb_"
      },
      "id": "6A8MWDLyujb_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (file.exists(\"/usr/local/lib/python3.7/dist-packages/google/colab/_ipython.py\")) { #may update python version occasionally\n",
        "  install.packages(\"R.utils\")\n",
        "  library(\"R.utils\")\n",
        "  library(\"httr\")\n",
        "  my_check <- function() {return(TRUE)}\n",
        "  reassignInPackage(\"is_interactive\", pkgName = \"httr\", my_check) \n",
        "  options(rlang_interactive=TRUE)\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xiHZNhPtb_A",
        "outputId": "7c16fa80-9246-4f2f-8c24-3cff9c547580"
      },
      "id": "-xiHZNhPtb_A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_auth(use_oob = TRUE, cache = FALSE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpMTdWXPvpqG",
        "outputId": "33f4bb12-9e85-4d48-d054-2653f033a339"
      },
      "id": "LpMTdWXPvpqG",
      "execution_count": 37,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Please point your browser to the following url: \n",
            "\n",
            "https://accounts.google.com/o/oauth2/auth?client_id=603366585132-dpeg5tt0et3go5of2374d83ifevk5086.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&login_hint=abzer.kelmina%40gmail.com\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter authorization code: 4/1AdQt8qgLywP7lSuy-Baa3QSRLtV4tbC-qJbPy5s4fRLBw5IbxRtYdHVpJbA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "getwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zOQ6CiT2v5PM",
        "outputId": "80ffeb39-3f67-4ea1-ab31-ccd6df3c071d"
      },
      "id": "zOQ6CiT2v5PM",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'/content'"
            ],
            "text/markdown": "'/content'",
            "text/latex": "'/content'",
            "text/plain": [
              "[1] \"/content\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_ls('Files for Summer School_Xenobiotic metabolism')$name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "D1ULQCN_5O9n",
        "outputId": "0809abe4-c2b3-406c-ec12-c89a8f980038"
      },
      "id": "D1ULQCN_5O9n",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'MZmine Files'</li><li>'GNPS Files'</li><li>'Data CleanUp Jupyter Notebook output'</li><li>'Xenobiotic_Metabolism_metadata.txt'</li><li>'Data_CleanUp_SummerSchool_Metabolomics.ipynb'</li></ol>\n"
            ],
            "text/markdown": "1. 'MZmine Files'\n2. 'GNPS Files'\n3. 'Data CleanUp Jupyter Notebook output'\n4. 'Xenobiotic_Metabolism_metadata.txt'\n5. 'Data_CleanUp_SummerSchool_Metabolomics.ipynb'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'MZmine Files'\n\\item 'GNPS Files'\n\\item 'Data CleanUp Jupyter Notebook output'\n\\item 'Xenobiotic\\_Metabolism\\_metadata.txt'\n\\item 'Data\\_CleanUp\\_SummerSchool\\_Metabolomics.ipynb'\n\\end{enumerate*}\n",
            "text/plain": [
              "[1] \"MZmine Files\"                                \n",
              "[2] \"GNPS Files\"                                  \n",
              "[3] \"Data CleanUp Jupyter Notebook output\"        \n",
              "[4] \"Xenobiotic_Metabolism_metadata.txt\"          \n",
              "[5] \"Data_CleanUp_SummerSchool_Metabolomics.ipynb\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x <- drive_get(\"~/Files for Summer School_Xenobiotic metabolism/MZmine Files/Xenobiotic_Metabolism_ChemProp2_GapFilled_QuantTable.csv\")\n",
        "drive_download(x)\n",
        "z <- read.csv(\"/content/Xenobiotic_Metabolism_ChemProp2_GapFilled_QuantTable.csv\")\n",
        "head(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "S8S5bZu67vRM",
        "outputId": "079301e8-f4cb-4d94-ae7f-013bb46457a5"
      },
      "id": "S8S5bZu67vRM",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "→ Files retrieved so far: 100\n",
            "\n",
            "\u001b[32m✔\u001b[39m The input `path` resolved to exactly 1 file.\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error: Path exists and overwrite is FALSE\nTraceback:\n",
            "1. drive_download(x)",
            "2. request_make(request, httr::write_disk(path, overwrite = overwrite))",
            "3. gargle::request_make(x, ..., user_agent = drive_ua())",
            "4. method(url = x$url, body = x$body, x$token, encode = encode, \n .     user_agent, ...)",
            "5. handle_url(handle, url, ...)",
            "6. named(list(...))",
            "7. httr::write_disk(path, overwrite = overwrite)",
            "8. stop(\"Path exists and overwrite is FALSE\", call. = FALSE)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(readr)"
      ],
      "metadata": {
        "id": "nUUqzbxu8VqR"
      },
      "id": "nUUqzbxu8VqR",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "f10168b7",
      "metadata": {
        "id": "f10168b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "1c985fd2-0785-45ec-d6a8-e231e6421b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning message in file(file, \"rt\"):\n",
            "“cannot open file '/content/Xenobiotic_Metabolism_metadata.txt': No such file or directory”\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ERROR",
          "evalue": "ignored",
          "traceback": [
            "Error in file(file, \"rt\"): cannot open the connection\nTraceback:\n",
            "1. read.csv(\"/content/Xenobiotic_Metabolism_metadata.txt\", sep = \"\\t\")",
            "2. read.table(file = file, header = header, sep = sep, quote = quote, \n .     dec = dec, fill = fill, comment.char = comment.char, ...)",
            "3. file(file, \"rt\")"
          ]
        }
      ],
      "source": [
        "md <- drive_get(\"~/Files for Summer School_Xenobiotic metabolism/MZmine Files/Xenobiotic_Metabolism_ChemProp2_GapFilled_QuantTable.csv\")\n",
        "drive_download(md)\n",
        "md <- read.csv('/content/Xenobiotic_Metabolism_metadata.txt',sep='\\t') \n",
        "head(md)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a31eafc",
      "metadata": {
        "id": "3a31eafc"
      },
      "source": [
        "## Reading the input data using URL (from Github):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7988ffd6",
      "metadata": {
        "id": "7988ffd6"
      },
      "outputs": [],
      "source": [
        "## Non-gap filled\n",
        "nft_url <- 'https://raw.githubusercontent.com/madeleineernst/Metabolomics_SummerSchool_2022/main/data/MZmine/Xenobiotic_Metabolism_ChemProp2_NonGapFilled_QuantTable.csv'\n",
        "## Gap filled\n",
        "ft_url <- 'https://raw.githubusercontent.com/madeleineernst/Metabolomics_SummerSchool_2022/main/data/MZmine/Xenobiotic_Metabolism_ChemProp2_GapFilled_QuantTable.csv'\n",
        "md_url <- 'https://raw.githubusercontent.com/madeleineernst/Metabolomics_SummerSchool_2022/main/data/Xenobiotic_Metabolism_metadata.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad9e910",
      "metadata": {
        "id": "3ad9e910"
      },
      "outputs": [],
      "source": [
        "nft <- read.csv(nft_url, header = T, check.names = F)\n",
        "ft <- read.csv(ft_url, header = T, check.names = F)\n",
        "md <- read.csv(md_url, header = T, check.names = F, sep = '\\t')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "863a44d4",
      "metadata": {
        "id": "863a44d4"
      },
      "source": [
        "## Setting a local working directory and creating an automatic result directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4734f4b6",
      "metadata": {
        "id": "4734f4b6"
      },
      "outputs": [],
      "source": [
        "# setting the current directory as the working directory\n",
        "Directory <- normalizePath(readline(\"Enter the path of the folder with input files: \"),\"/\",mustWork=FALSE)\n",
        "setwd(Directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0436b28",
      "metadata": {
        "id": "e0436b28"
      },
      "outputs": [],
      "source": [
        "getwd() #to get the working directory "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd010938",
      "metadata": {
        "id": "dd010938"
      },
      "outputs": [],
      "source": [
        "# Getting all the files in the folder\n",
        "dirs <- dir(path=paste(getwd(), sep=\"\"), full.names=TRUE, recursive=TRUE)\n",
        "folders <- unique(dirname(dirs))\n",
        "files <- list.files(folders, full.names=TRUE)\n",
        "files_1 <- basename((files))\n",
        "files_2 <- dirname((files))\n",
        "# Creating a Result folder\n",
        "dir.create(path=paste(files_2[[1]], \"_Results\", sep=\"\"), showWarnings = TRUE)\n",
        "fName <-paste(files_2[[1]], \"_Results\", sep=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55ab1133",
      "metadata": {
        "id": "55ab1133"
      },
      "source": [
        "**<font color='red'> In the following line, enter the required file ID numbers separated by commas. For example as: 1,2,3 </font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d07e82",
      "metadata": {
        "id": "45d07e82"
      },
      "outputs": [],
      "source": [
        "print(files_1)\n",
        "input <- as.double(unlist(strsplit(readline(\"Specify the ID numbers of feature-file, metadata:\"), split=\",\")))\n",
        "\n",
        "#Gets the extension of each file. Ex:csv\n",
        "pattern <- c()\n",
        "for (i in files_1){\n",
        "  sep_file <- substr(i, nchar(i)-2,nchar(i))\n",
        "  pattern <- rbind(pattern,sep_file)\n",
        "}\n",
        "#pattern\n",
        "\n",
        "ft <- read.csv(files_1[input[1]],sep = ifelse(pattern[input[1]]!=\"csv\",\"\\t\",\",\"), header=TRUE,check.names = FALSE) # By applying 'row.names = 1', the 1st column 'ID' becomes the row names\n",
        "md <-read.csv(files_1[input[2]], sep = ifelse(pattern[input[2]]!=\"csv\",\"\\t\",\",\"), header=TRUE,check.names = FALSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00da9db7",
      "metadata": {
        "id": "00da9db7"
      },
      "outputs": [],
      "source": [
        "#If you have cluster_info file:\n",
        "if(readline(\"Do you have non gap-filled feature table? Y/N:\")==\"Y\"){\n",
        "  nft <- as.double(readline(\"Enter the ID number of non-gap-filled feature file:\"))\n",
        "  nft<- read.csv(files_1[nft],sep=ifelse(pattern[nft]!=\"csv\",\"\\t\",\",\"), header = TRUE,check.names = FALSE)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f12e24c",
      "metadata": {
        "id": "4f12e24c"
      },
      "source": [
        "Lets check if the data has been read correclty!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "429ff705",
      "metadata": {
        "id": "429ff705"
      },
      "outputs": [],
      "source": [
        "head(ft)\n",
        "dim(ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864b7231",
      "metadata": {
        "id": "864b7231"
      },
      "outputs": [],
      "source": [
        "head(nft)\n",
        "dim(nft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7bf0865",
      "metadata": {
        "id": "a7bf0865"
      },
      "outputs": [],
      "source": [
        "head(md)\n",
        "dim(md)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f19073e0",
      "metadata": {
        "id": "f19073e0"
      },
      "source": [
        "Trying to bring the feature table and metadata in the correct format:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ffd93c",
      "metadata": {
        "id": "25ffd93c"
      },
      "outputs": [],
      "source": [
        "#Removing Peak area extensions\n",
        "colnames(ft) <- gsub(' Peak area','',colnames(ft))\n",
        "colnames(nft) <- gsub(' Peak area','',colnames(nft))\n",
        "md$filename<- gsub(' Peak area','',md$filename)\n",
        "\n",
        "#Removing if any NA columns present in the md file\n",
        "md <- md[,colSums(is.na(md))<nrow(md)]\n",
        "\n",
        "#Changing the row names of the files\n",
        "rownames(md) <- md$filename\n",
        "md <- md[,-1]\n",
        "rownames(ft) <- paste(ft$'row ID',round(ft$'row m/z',digits = 3),round(ft$'row retention time',digits = 3), sep = '_')\n",
        "rownames(nft) <- paste(nft$'row ID',round(nft$'row m/z',digits = 3),round(nft$'row retention time',digits = 3), sep = '_')\n",
        "\n",
        "#Picking only the files with column names containing 'mzML'\n",
        "ft <- ft[,grep('mzML',colnames(ft))]\n",
        "nft <- nft[,grep('mzML',colnames(nft))]\n",
        "\n",
        "# Converting replicate attributes into factors (categorical data)\n",
        "md$ATTRIBUTE_replicates <- as.factor(md$ATTRIBUTE_replicates)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e927cf45",
      "metadata": {
        "id": "e927cf45"
      },
      "source": [
        "Lets check the files once again!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e76fb0e3",
      "metadata": {
        "id": "e76fb0e3"
      },
      "outputs": [],
      "source": [
        "head(nft)\n",
        "dim(nft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "499d8a48",
      "metadata": {
        "id": "499d8a48"
      },
      "outputs": [],
      "source": [
        "head(ft)\n",
        "dim(ft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55093982",
      "metadata": {
        "id": "55093982"
      },
      "outputs": [],
      "source": [
        "head(md)\n",
        "dim(md)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96275453",
      "metadata": {
        "id": "96275453"
      },
      "source": [
        "### Creating a function named FrequencyPlot:  \n",
        "The below function takes in the two input datatables: for example, gapfilled and non-gapfilled, calculates the frequency distribution of the data in the order of 10 and produces a grouped barplot showing the distribution as output. The frequency plot shows where the features are present in higher number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6d2b3b4",
      "metadata": {
        "id": "e6d2b3b4"
      },
      "outputs": [],
      "source": [
        "#'Global' settings for plot size in the output cell\n",
        "options(repr.plot.width=10, repr.plot.height=8,res=600) #For google collab\n",
        "#options(repr.plot.width=5, repr.plot.height=3) #For Jupyter Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4755a764",
      "metadata": {
        "id": "4755a764"
      },
      "outputs": [],
      "source": [
        "FrequencyPlot <- function(x1,x2){\n",
        "  \n",
        "   #creating bins from -1 to 10^10 using sequence function seq()\n",
        "    bins <- c(-1,0,(1 * 10^(seq(0,10,1)))) \n",
        "    \n",
        "    #cut function cuts the give table into its appropriate bins\n",
        "    scores_x1 <- cut(as.matrix(x1),bins,labels = c('0','1','10','1E2','1E3','1E4','1E5','1E6','1E7','1E8','1E9','1E10')) \n",
        "    \n",
        "    #transform function convert the tables into a column format: easy for visualization \n",
        "    Table_x1<-transform(table(scores_x1)) #contains 2 columns: \"scores_x1\", \"Freq\"\n",
        "    \n",
        "    #Repeating the same steps for x2\n",
        "    scores_x2 <- cut(as.matrix(x2),bins,labels = c('0','1','10','1E2','1E3','1E4','1E5','1E6','1E7','1E8','1E9','1E10'))\n",
        "    Table_x2<-transform(table(scores_x2))\n",
        "  \n",
        "    #Getting the names of x1 and x2\n",
        "    arg1 <- deparse(substitute(x1))\n",
        "    arg2 <-deparse(substitute(x2))\n",
        "    \n",
        "    #Creating a data frame for plotting\n",
        "    data_plot <- as.data.frame(c(Table_x1$Freq,Table_x2$Freq)) #Concatenating the frequency info of both tables rowwise\n",
        "    colnames(data_plot) <- \"Freq\" #naming the 1st column as 'Freq'\n",
        "    data_plot$Condition <- c(rep(arg1,12),rep(arg2,12)) #adding a 2nd column 'Condition', which just repeats the name of x1 and x2 accordingly\n",
        "    data_plot$Range_bins <- rep(Table_x1$scores_x1,2) #Adding 3rd column 'Range Bins'\n",
        "    data_plot$Log_Freq <- log(data_plot$Freq+1) #Log scaling the frequency values\n",
        "    \n",
        "    ## GGPLOT2\n",
        "    BarPlot <- ggplot(data_plot, aes(Range_bins, Log_Freq, fill = Condition)) + \n",
        "    geom_bar(stat=\"identity\", position = \"dodge\", width=0.4) + \n",
        "    scale_fill_brewer(palette = \"Set1\") +\n",
        "    ggtitle(label=\"Frequency plot\") +\n",
        "    xlab(\"Range\") + ylab(\"(Log)Frequency\") + labs(fill = \"Data Type\") + \n",
        "    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +   # setting the angle for the x label\n",
        "    theme(axis.text.y = element_text(angle = 45, vjust = 0.5, hjust=1)) +   # setting the angle for the y label\n",
        "    theme(plot.title = element_text(hjust = 0.5)) # centering the plot title\n",
        "  \n",
        "    print(BarPlot)\n",
        "}  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea08fc3d",
      "metadata": {
        "id": "ea08fc3d"
      },
      "source": [
        "**About the experiment:**\n",
        "- Bacteria (B.subtilis and E.coli) were treated with a pool of antibiotics (Sulfamethoxazole, sulfadimethoxine, cyproconazole) including a herbicide Asulam, taken at a concentration lower than their MIC (minimum inhibitory concentration).\n",
        "- The samples were collected at different timepoints, the compounds were extracted (with 50% EtOAc) and measured using LC-MS/MS.\n",
        "- The goal of the experiment was to look for any potential biotransformation. eg: Drug or xenobiotic metabolism"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43099574",
      "metadata": {
        "id": "43099574"
      },
      "source": [
        "## Blank Removal:\n",
        "\n",
        "(Note: In LC-MS/MS, we use solvents also called as Blanks which are usually injected time-to-time to prevent carryover of the sample) </br>\n",
        "\n",
        "For the Blank removal step, we need to split the data as control and samples. </br>\n",
        "\n",
        "**The blanks we are referring to here, is the control blanks in the experiment and not the LC-MS/MS blanks.**\n",
        "- The control blanks here is the sample without treatment. \n",
        "- Samples are biological replicates with treatment and we have two sets of data: B.sub and E.coli. </br>\n",
        "\n",
        "In general, having multiple control blanks helps us to compare any variation in the data. Comparing control to the sample helps us to identify the background features that contribute to any technical variation. A common filtering method is to use a cutoff to remove features that are not present sufficient enough in our biological samples.\n",
        "\n",
        "1. We find an average for all the feature intensities in your control set and sample set.\n",
        "Therefore, for n no.of features in a control or sample set, we get n no.of averaged features.\n",
        "2. Next, we get a ratio of this average_control vs average_sample. This ratio Control/sample tells us how much of that particular feature of a sample gets its contribution from control. If it is more than 30% (or Cutoff as 0.3), we consider the feature as noise.\n",
        "3. The resultant information (if ratio > Cutoff or not) is stored in a bin\n",
        "4. We count the no.of features in the bin that satisfies the condition ratio > cutoff, and consider those features as 'noise or background features'.\n",
        "5. We also try to visualize the frequency distribution in our data Ctrl and samples\n",
        "\n",
        "For a dataset containing several batches, the filtering steps are performed batch-wise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ffdb64e6",
      "metadata": {
        "id": "ffdb64e6"
      },
      "outputs": [],
      "source": [
        "input_data <-ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84bdaab8",
      "metadata": {
        "id": "84bdaab8"
      },
      "outputs": [],
      "source": [
        "Ctrl <-  input_data[,grep('_C',colnames(input_data))]\n",
        "Samples <- input_data[,-grep('_C',colnames(input_data))]\n",
        "\n",
        "dim(Ctrl)\n",
        "dim(Samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed6bb33",
      "metadata": {
        "id": "9ed6bb33"
      },
      "source": [
        "### Similarly, we can also subset the data belonging to only one batch, for ex:\"B.subtilis\", for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59a2c78e",
      "metadata": {
        "id": "59a2c78e"
      },
      "outputs": [],
      "source": [
        "head(md)\n",
        "print(matrix(data=colnames(md),nrow=length(colnames(md))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbf43655",
      "metadata": {
        "id": "fbf43655"
      },
      "outputs": [],
      "source": [
        "Condition <- as.double(unlist(strsplit(readline(\"Enter the IDs of interested attributes separated by commas:\"),split=\",\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c15faf19",
      "metadata": {
        "id": "c15faf19"
      },
      "outputs": [],
      "source": [
        "#Specifying which conditions to keep under the selected attributes\n",
        "\n",
        "Meta_Filtered <-md\n",
        "for(i in 1:length(Condition)){\n",
        "    \n",
        "    #Shows the different levels within each selected condition:\n",
        "    Levels_Cdtn <- levels(as.factor(Meta_Filtered[,Condition[i]]))\n",
        "    print(matrix(Levels_Cdtn,length(Levels_Cdtn)))\n",
        "    \n",
        "    #These lines are not needed in R console, but in Jupyter Notebook to get the previous print statement working\n",
        "    flush.console()  \n",
        "    Sys.sleep(0.2)\n",
        "    \n",
        "    #Among the shown levels of ana ttribute, select the ones to keep\n",
        "    Cdtn <- as.double(unlist(strsplit(readline(\"Enter the IDs of condition(s) you want to KEEP (separated by commas):\"), split=',')))\n",
        "    Levels_Cdtn[Cdtn]\n",
        "    \n",
        "    #Selecting only rows in meta_filtered that match the condition\n",
        "    Meta_Filtered <- Meta_Filtered[(Meta_Filtered[,Condition[i]] == Levels_Cdtn[Cdtn]),]\n",
        "  }\n",
        "\n",
        "#Removing all the rows with only NAs\n",
        "Meta_Condition <- subset(Meta_Filtered,rowSums(is.na(Meta_Filtered))!=ncol(Meta_Filtered))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "117bf7f9",
      "metadata": {
        "id": "117bf7f9"
      },
      "outputs": [],
      "source": [
        "head(Meta_Condition)\n",
        "dim(Meta_Condition)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4c4d9ff",
      "metadata": {
        "id": "d4c4d9ff"
      },
      "outputs": [],
      "source": [
        "#Picking only the columns in ft that are same as rownames in final metadata\n",
        "ft_Condition <- input_data[,which(colnames(input_data)%in%rownames(Meta_Final))] "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6ad2dec",
      "metadata": {
        "id": "c6ad2dec"
      },
      "source": [
        "Now we can continue splitting the batch data into control and sample and proceed with next steps:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d203a0d1",
      "metadata": {
        "id": "d203a0d1"
      },
      "outputs": [],
      "source": [
        "input_data<- ft_Condition\n",
        "Ctrl <-  input_data[,grep('_C',colnames(input_data))]\n",
        "Samples <- input_data[,-grep('_C',colnames(input_data))]\n",
        "\n",
        "dim(Ctrl)\n",
        "dim(Samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59b5482f",
      "metadata": {
        "id": "59b5482f"
      },
      "source": [
        "<font color='red'>Note: The Cutoff value chosen for getting the files in the folder **Preprocessing Jupyter Output files-Data CleanUp** in the github: 0.9 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af1aa72f",
      "metadata": {
        "id": "af1aa72f"
      },
      "outputs": [],
      "source": [
        "if(readline('Do you want to perform Blank Removal- Y/N:')=='Y'){\n",
        "    \n",
        "    #When cutoff is low, more noise (or background) detected; With higher cutoff, less background detected, thus more features observed\n",
        "    Cutoff <- as.numeric(readline('Enter Cutoff value between 0.1 & 1:')) # (i.e. 10% - 100%). Ideal cutoff range: 0.1-0.3\n",
        "    \n",
        "    #Getting mean for every feature in Ctrl and Samples\n",
        "    Avg_ctrl <- rowMeans(Ctrl, na.rm= FALSE, dims = 1) # set na.rm = FALSE to check if there are NA values. When set as TRUE, NA values are changed to 0\n",
        "    Avg_samples <- rowMeans(Samples, na.rm= FALSE, dims = 1)\n",
        "    \n",
        "    #Getting the ratio of Ctrl vs Sample\n",
        "    Ratio_Ctrl_Sample <- (Avg_ctrl+1)/(Avg_samples+1)\n",
        "    \n",
        "    # Creating a bin with 1s when the ratio>Cutoff, else put 0s\n",
        "    Bg_bin <- ifelse(Ratio_Ctrl_Sample > Cutoff, 1, 0 )\n",
        "\n",
        "\n",
        "    # Checking if there are any NA values present. Having NA values in the 4 variables will affect the final dataset to be created\n",
        "    temp_NA_Count <-cbind(Avg_ctrl ,Avg_samples,Ratio_Ctrl_Sample,Bg_bin)\n",
        "    \n",
        "    print('No of NA values in the following columns:')\n",
        "    print(colSums(is.na(temp_NA_Count)))\n",
        "\n",
        "     #Calculating the number of background features and features present\n",
        "    Bg_Features <- sum(Bg_bin ==1,na.rm = TRUE)\n",
        "    No_of_Features <- nrow(input_data) - Bg_Features\n",
        "    \n",
        "    print(paste(\"No.of Background or noise features:\",Bg_Features))\n",
        "    print(paste(\"No.of features after excluding noise:\",No_of_Features)) \n",
        "\n",
        "    input_data1 <- cbind(as.matrix(input_data),Bg_bin)    \n",
        "    plot_CtrlSample <- FrequencyPlot(Samples,Ctrl)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91c2d128",
      "metadata": {
        "id": "91c2d128"
      },
      "source": [
        "**TO NOTE:** We have not yet removed the blanks. We have just calculated the noise features according to our cutoff and these will be eliminated in the later steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4210007",
      "metadata": {
        "id": "b4210007"
      },
      "source": [
        "### Imputation: \n",
        "\n",
        "For several reasons, real world datasets might have some missing values in it, in the form of NA, NANs or 0s. Eventhough the gapfilling step of MZmine fills the missing values, we still end up with some missing values or 0s in our feature table. This could be problematic for statistical analysis. \n",
        "In order to have a better dataset, we cannot simply discard those rows or columns with missing values as we will lose a chunk of our valuable data.\n",
        "Instead we can try imputing those missing values. Imputation involves replacing the missing values in the data with a meaningful, reasonable guess. There are several methods, such as:  \n",
        "1) Mean imputation (replacing the missing values in a column with the mean or average of the column)  \n",
        "2) Replacing it with the most frequent value  \n",
        "3) Several other machine learning imputation methods such as k-nearest neighbors algorithm(k-NN), Hidden Markov Model(HMM)\n",
        "\n",
        "One such method, we are going to use is: **to replace the zeros from the gapfilled quant table with the non-gap filled table** we get from MZmine. In order to do that, we can visualize our data distribution using the frequenct plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d83ae53",
      "metadata": {
        "id": "9d83ae53"
      },
      "outputs": [],
      "source": [
        "GapFilled <- input_data\n",
        "NotGapFilled <- nft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e527abdb",
      "metadata": {
        "id": "e527abdb"
      },
      "outputs": [],
      "source": [
        "if(readline('Do you want to perform Imputation with minimum value of NonGapFilled table? - Y/N:')=='Y'){\n",
        "    \n",
        "    plot<- FrequencyPlot(GapFilled,NotGapFilled)\n",
        "    \n",
        "    Arg1 = plot$data$Condition[1]\n",
        "    Arg2 = plot$data$Condition[13]\n",
        "    \n",
        "    # accessing the datatable of plot and subsetting with the condition: Eliminating the Range (or bin) 0 and Ranges with zero frequencies \n",
        "    plotData_New <- subset(plot$data,plot$data$Freq!=0 & plot$data$Range_bins !=0) \n",
        "    \n",
        "    #getting the first appearing value of this new plot datatable\n",
        "    First_val_temp <- aggregate(plotData_New$Freq, by=list(plotData_New$Condition), FUN=first) \n",
        "    \n",
        "    # Subsetting the rows in the plotData_New that has the first appearing values\n",
        "    First_val <- plotData_New[plotData_New$Freq %in% c(First_val_temp$x[1],First_val_temp$x[2]),]\n",
        "  \n",
        "    print(paste0(\"The Range with a minimum value greater than 0 for \",Arg1,\":\", First_val$Range_bins[1]))\n",
        "    print(paste0(\"The Range with a minimum value greater than 0 for \",Arg2,\":\", First_val$Range_bins[2]))\n",
        "    \n",
        "    # getting the 2nd minimum value of non-gap filled data. (The first minimum value in the data table is usually zero)\n",
        "    RawLOD <- round(min(NotGapFilled[NotGapFilled!=min(NotGapFilled)])) \n",
        "    \n",
        "    print(paste0(\"The minimum value in the Non-gap filled data other than 0 : \",RawLOD))\n",
        "    GapFilled[GapFilled==0 | GapFilled<RawLOD] <- RawLOD # Replacing zeros in the gap-filled file as well as values<RawLOD with RawLOD\n",
        "    RawLOD_Table <- GapFilled\n",
        "    \n",
        "    #write.csv(RawLOD_Table, file=paste0('Quant_Table_filled_with_MinValue_',RawLOD,'_NotGapFilled','.csv'),row.names =FALSE) \n",
        "    \n",
        "    input_data <- GapFilled\n",
        "} else input_data <- GapFilled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7eac20d",
      "metadata": {
        "id": "e7eac20d"
      },
      "source": [
        "### Imputation with a Cutoff LOD:\n",
        "Previously we have replaced the zeros in our ft(gapfilled) with the minimum value in nft(non gapfilled). Ex: 3766.<br>\n",
        "\n",
        "Instead, we can also only use ft and see the frquency distribution of its features with the frequency plot. The frequency plot shows where the features are present in higher number.\n",
        "\n",
        "For ex: If until range 10-100, (shown in the figure as 1E2) there are no or very less features, we want to exclude until that range and consider from range (100-1000), or, in other words, '1E3' or '1000' as Cutoff_LOD. This value will be used to replace the zeros in the data table.\n",
        "\n",
        "The following step asks if the imputation was already performed, if so, it takes that value as the Cutoff_LOD, else, we get to specify our Cutoff_LOD based on the frequency plot.\n",
        "Once we have our Cutoff_LOD:\n",
        "- We create  a temporary dataset with all the feature intensites of your sample (not the ctrl, only the sample) and checking it against the cutoff_LOD value. If it is less than the cutoff_LOD, we replace it with cutoff_LOD. Thus, for instance, if we take 1000 as cutoff_LOD, our sample data will be filled with a bunch of 1000s now instead of zeros.\n",
        "- Then we create a Final dataset using the temporary dataset. Here, we try to see if each feature from all samples is noise or not (from step 4 under Blank Removal), if it noise, we replace the feature with cutoff_LOD, else we keep the info from the temporary dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4de72398",
      "metadata": {
        "id": "4de72398"
      },
      "outputs": [],
      "source": [
        "Cutoff_LOD <-ifelse(readline(\"Was Imputation step already performed? Y/N :\")==\"Y\",RawLOD,as.numeric(readline(\"Enter your Cutoff LOD here:\")))  #Enter the LOD value as seen in the frequency plot\n",
        "temp_matrix <- c()\n",
        "for (i in 1:ncol(Samples)){ \n",
        "    \n",
        "    #Replacing the Sample intensities with Cutoff_LOD, if they are lower than Cutoff_LOD\n",
        "    x <- ifelse(Samples[,i] > Cutoff_LOD, Samples[,i],Cutoff_LOD)\n",
        "    temp_matrix <- cbind(temp_matrix,as.matrix(x))\n",
        "}\n",
        "colnames(temp_matrix) <- colnames(Samples)\n",
        "  \n",
        "Final_matrix <-c()\n",
        "for (i in 1:ncol(temp_matrix)){\n",
        "    \n",
        "     #Replacing the feature row with Cutoff_LOD if its Bg_bin value is 1, indicating it as noise, else retain the temporary dataset as such.\n",
        "    x <-ifelse(input_data1[,ncol(input_data1)] ==1, Cutoff_LOD, temp_matrix[,i])\n",
        "    Final_matrix <-cbind(Final_matrix,x)\n",
        "}\n",
        "colnames(Final_matrix) <- colnames(Samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed071fa7",
      "metadata": {
        "id": "ed071fa7"
      },
      "outputs": [],
      "source": [
        "write.csv(Final_matrix,file.path(fName, paste0('Processed_QuantTable_filled_with_',Cutoff_LOD,'_CutOff_Used_',Cutoff,'_Bsub','.csv')),row.names =TRUE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "720cdc75",
      "metadata": {
        "id": "720cdc75"
      },
      "outputs": [],
      "source": [
        "head(Final_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f428856",
      "metadata": {
        "id": "8f428856"
      },
      "outputs": [],
      "source": [
        "#removing all the rows with only cutoff values:\n",
        "#Final_matrix<-Final_matrix[rowMeans(Final_matrix)!= Cutoff_LOD,]  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f06a2dd7",
      "metadata": {
        "id": "f06a2dd7"
      },
      "source": [
        "## Normalization:\n",
        "The following code performs sample-centric (column-wise) normalisation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a008a7a",
      "metadata": {
        "id": "3a008a7a"
      },
      "outputs": [],
      "source": [
        "if (readline(\"Do you want to perform Normalization: Y/N:\") == 'Y'){\n",
        "    input_data <- Final_matrix\n",
        "    \n",
        "    #Getting column-wise sums of the input-data\n",
        "    sample_sum <- colSums(input_data, na.rm= TRUE, dims = 1)\n",
        "    \n",
        "    #Dividing each element of a particular column with its column sum\n",
        "    Normalized_data <- c()\n",
        "    for (i in 1:ncol(input_data)){\n",
        "        x <- input_data[,i] / sample_sum[i]\n",
        "        Normalized_data <- cbind(Normalized_data, x)\n",
        "    }\n",
        "    colnames(Normalized_data) <- names(sample_sum)\n",
        "\n",
        "} else return(Final_matrix)\n",
        "  \n",
        "print(paste('No.of NA values in Normalized data:',sum(is.na(Normalized_data)== TRUE)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58fc407e",
      "metadata": {
        "id": "58fc407e"
      },
      "outputs": [],
      "source": [
        "write.csv(Normalized_data,file.path(fName,'Normalised_Quant_table.csv'),row.names =TRUE) "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.1"
    },
    "colab": {
      "name": "20220715_Data_CleanUp_SummerSchool_Metabolomics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}