{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10168b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages if not present\n",
    "install.packages('dplyr')\n",
    "install.packages('ggplot2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7988ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Non-gap filled\n",
    "nft_url <- 'https://raw.githubusercontent.com/madeleineernst/Metabolomics_SummerSchool_2022/main/data/MZmine/Xenobiotic_Metabolism_ChemProp2_NonGapFilled_QuantTable.csv'\n",
    "## Gap filled\n",
    "ft_url <- 'https://raw.githubusercontent.com/madeleineernst/Metabolomics_SummerSchool_2022/main/data/MZmine/Xenobiotic_Metabolism_ChemProp2_GapFilled_QuantTable.csv'\n",
    "md_url <- 'https://raw.githubusercontent.com/madeleineernst/Metabolomics_SummerSchool_2022/main/data/Xenobiotic_Metabolism_metadata.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9e910",
   "metadata": {},
   "outputs": [],
   "source": [
    "nft <- read.csv(nft_url, header = T, check.names = F)\n",
    "ft <- read.csv(ft_url, header = T, check.names = F)\n",
    "md <- read.csv(md_url, header = T, check.names = F, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ff705",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864b7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(nft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bf0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b14c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Peak area extensions\n",
    "colnames(ft) <- gsub(' Peak area','',colnames(ft))\n",
    "colnames(nft) <- gsub(' Peak area','',colnames(nft))\n",
    "md$filename <- gsub(' Peak area','',md$filename)\n",
    "\n",
    "#Removing if any NA columns present in the md file\n",
    "md <- md[,colSums(is.na(md))<nrow(md)]\n",
    "\n",
    "#Changing the row names of the files\n",
    "rownames(md) <- md$filename\n",
    "rownames(ft) <- paste(ft$'row ID',round(ft$'row m/z',digits = 3),round(ft$'row retention time',digits = 3), sep = '_')\n",
    "rownames(nft) <- paste(nft$'row ID',round(nft$'row m/z',digits = 3),round(nft$'row retention time',digits = 3), sep = '_')\n",
    "\n",
    "#Picking only the files with column names containing 'mzML'\n",
    "ft <- ft[,grep('mzML',colnames(ft))]\n",
    "nft <- nft[,grep('mzML',colnames(nft))]\n",
    "\n",
    "# Converting replicate attributes into factors (categorical data)\n",
    "md$ATTRIBUTE_replicates <- as.factor(md$ATTRIBUTE_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76fb0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(nft)\n",
    "dim(nft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d8a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(ft)\n",
    "dim(ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96275453",
   "metadata": {},
   "source": [
    "### Creating a function named FrequencyPlot:  \n",
    "The below function takes in the two input datatables: gapfilled and non-gapfilled, calculates the frequency distribution of the data in the order of 10 and produces a grouped barplot showing the distribution as output. The frequency plot shows where the features are present in higher number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4755a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=5, repr.plot.height=3) #'global' settings for plot size in the output cell\n",
    "\n",
    "FrequencyPlot <- function(x1,x2){\n",
    "  \n",
    "  bins <- c(-1,0,(1 * 10^(seq(0,10,1)))) #creating bins from -1 to 10^10 using sequence function: seq()\n",
    "  \n",
    "  scores_x1 <- cut(as.matrix(x1),bins,labels = c('0','1','10','1E2','1E3','1E4','1E5','1E6','1E7','1E8','1E9','1E10')) #cut function store the data into the appropriate bins\n",
    "  Table_x1<-transform(table(scores_x1)) #transform function convert the tables into column format: easy for visualization\n",
    "  \n",
    "  # Repeating the same steps for x2\n",
    "  scores_x2 <- cut(as.matrix(x2),bins,labels = c('0','1','10','1E2','1E3','1E4','1E5','1E6','1E7','1E8','1E9','1E10'))\n",
    "  Table_x2<-transform(table(scores_x2))\n",
    "  \n",
    "  arg1 <- deparse(substitute(x1))\n",
    "  arg2 <-deparse(substitute(x2))\n",
    "  \n",
    "  data_plot <- as.data.frame(c(Table_x1$Freq,Table_x2$Freq))\n",
    "  colnames(data_plot) <- \"Freq\"\n",
    "  data_plot$Condition <- c(rep(arg1,12),rep(arg2,12))\n",
    "  data_plot$Range_bins <- rep(Table_x1$scores_x1,2)\n",
    "  data_plot$Log_Freq <- log(data_plot$Freq+1) #Log scaling the frequency values\n",
    "  \n",
    "  ## GGPLOT2\n",
    "   BarPlot <- ggplot(data_plot, aes(Range_bins, Log_Freq, fill = Condition)) + \n",
    "    geom_bar(stat=\"identity\", position = \"dodge\", width=0.4) + \n",
    "    scale_fill_brewer(palette = \"Set1\") +\n",
    "    ggtitle(label=\"Frequency plot\") +\n",
    "    xlab(\"Range\") + ylab(\"(Log)Frequency\") + labs(fill = \"Data Type\") + \n",
    "    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +   # setting the angle for the x label\n",
    "    theme(axis.text.y = element_text(angle = 45, vjust = 0.5, hjust=1)) +   # setting the angle for the y label\n",
    "    theme(plot.title = element_text(hjust = 0.5)) # centering the plot title\n",
    "  \n",
    "  print(BarPlot)\n",
    "}  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4210007",
   "metadata": {},
   "source": [
    "**Imputation:** Replacing zeros from the gapfilled quant-table with the minimum value of non-gapfilled table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "GapFilled <- ft\n",
    "NotGapFilled <- nft\n",
    "\n",
    "if(readline('Do you want to perform Imputation - Y/N:')=='Y'){\n",
    "    \n",
    "    plot<- FrequencyPlot(GapFilled,NotGapFilled)\n",
    "    \n",
    "    Arg1 = plot$data$Condition[1]\n",
    "    Arg2 = plot$data$Condition[13]\n",
    "    plotData_New <- subset(plot$data,plot$data$Freq!=0 & plot$data$Range_bins !=0) # accessing the datatable of plot and subsetting with the condition: Eliminating the Range (or bin) 0 and Ranges with zero frequencies \n",
    "    First_val_temp <- aggregate(plotData_New$Freq, by=list(plotData_New$Condition), FUN=first) #getting the first appearing value of this new plot datatable\n",
    "    First_val <- plotData_New[plotData_New$Freq %in% c(First_val_temp$x[1],First_val_temp$x[2]),] # Subsetting the rows in the plotData_New that has the first appearing values\n",
    "  \n",
    "    print(paste0(\"The Range with a minimum value greater than 0 for \",Arg1,\":\", First_val$Range_bins[1]))\n",
    "    print(paste0(\"The Range with a minimum value greater than 0 for \",Arg2,\":\", First_val$Range_bins[2]))\n",
    "    \n",
    "    RawLOD <- round(min(NotGapFilled[NotGapFilled!=min(NotGapFilled)])) # getting the 2nd minimum value of non-gap filled data. (The first minimum value in the data table is usually zero)\n",
    "    \n",
    "    print(paste0(\"The minimum value in the Non-gap filled data other than 0 : \",RawLOD))\n",
    "    GapFilled[GapFilled==0 | GapFilled<RawLOD] <- RawLOD # Replacing zeros in the gap-filled file as well as values<RawLOD with RawLOD\n",
    "    RawLOD_Table <- GapFilled\n",
    "    #write.csv(RawLOD_Table, file=paste0('Quant_Table_filled_with_MinValue_',RawLOD,'_NotGapFilled','.csv'),row.names =FALSE) \n",
    "    input_data <- GapFilled\n",
    "} else input_data <- GapFilled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43099574",
   "metadata": {},
   "source": [
    "## Blank Removal:\n",
    "Now, we have the resultant input_data, which is 'ft' filled with 3766 instead of 0s. For the next step, Blank removal, we need to split the data as control and samples.\n",
    "- The control here is the sample without treatment. \n",
    "- Samples are biological replicates with treatment and we have two sets of data in our file, B.sub and E.coli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdb64e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bdaab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctrl <-  input_data[,grep('_C',colnames(input_data))]\n",
    "Samples <- input_data[,-grep('_C',colnames(input_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1aa72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(readline('Do you want to perform Blank Removal- Y/N:')=='Y'){\n",
    "    \n",
    "    #When cutoff is low, more noise (or background) detected; With higher cutoff, less background detected, thus more features observed\n",
    "    Cutoff <- as.numeric(readline('Enter Cutoff value between 0.1 & 1:')) # (i.e. 10% - 100%). Ideal cutoff range: 0.1-0.3\n",
    "    \n",
    "    #Getting mean for every feature in Ctrl and Samples\n",
    "    Avg_ctrl <- rowMeans(Ctrl, na.rm= FALSE, dims = 1) # set na.rm = FALSE to check if there are NA values. When set as TRUE, NA values are changed to 0\n",
    "    Avg_samples <- rowMeans(Samples, na.rm= FALSE, dims = 1)\n",
    "    \n",
    "    #Getting the ratio of Ctrl vs Sample\n",
    "    Ratio_Ctrl_Sample <- (Avg_ctrl+1)/(Avg_samples+1)\n",
    "    \n",
    "    # Creating a bin with 1s when the ratio>Cutoff, else put 0s\n",
    "    Bg_bin <- ifelse(Ratio_Ctrl_Sample > Cutoff, 1, 0 )\n",
    "\n",
    "\n",
    "    # Checking if there are any NA values present. Having NA values in the 4 variables will affect the final dataset to be created\n",
    "    temp_NA_Count <-cbind(Avg_ctrl ,Avg_samples,Ratio_Ctrl_Sample,Bg_bin)\n",
    "    cat('NA values are present in:',names(which(colSums(is.na(temp_NA_Count))>0))) #prints the variable name if it has NA values\n",
    "\n",
    "     #Calculating the number of background features and features present\n",
    "    Bg_Features <- sum(Bg_bin ==1,na.rm = TRUE)\n",
    "    No_of_Features <- nrow(input_data) - Bg_Features\n",
    "    \n",
    "    print(paste(\"No.of Background or noise features:\",Bg_Features))\n",
    "    print(paste(\"No.of features after excluding noise:\",No_of_Features)) \n",
    "\n",
    "    input_data1 <- cbind(as.matrix(input_data),Bg_bin)    \n",
    "    plot_CtrlSample <- FrequencyPlot(Samples,Ctrl)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acca9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Ctrl)\n",
    "head(Samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eac20d",
   "metadata": {},
   "source": [
    "Previously we have replaced the zeros in our ft(gapfilled) with the minimum value in nft(non gapfilled). Ex: 3766\n",
    "\n",
    "The frequency plot shows where the features are present in higher number. We can only use ft and see the frquency distribution of its features with the frequency plot.\n",
    "For ex: if until 1E2 has no or really less features, the goal is to exclude until that range and consider only values from 1E3 range. Thus 1E3 will be taken as Cutoff_LOD (Limit of Detection). This value will eventually become the 'new zero'.  \n",
    "\n",
    "The following step asks if the imputation was already performed, if so, it takes that value as the Cutoff_LOD, else, we get to specify our Cutoff_LOD based on the frequency plot.\n",
    "Once we have our Cutoff_LOD,  \n",
    "--- We create  a temporary dataset checking all the feature intensites of our sample (only the sample, without control) and check it against the Cutoff_LOD. If it is less than the Cutoff_LOD, we replace it with Cutoff_LOD. Thus our sample data, for example, is with a bunch of 1000s (if our Cutoff_LOD=1000) instead of zeros  \n",
    "--- Then, we create a Final dataset using the temporary dataset. Here, we try to see if each feature from all samples is noise or not. If it noise, we replace it with Cutoff_LOD as well, else we keep the info from the temporary dataset as such. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de72398",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cutoff_LOD <-ifelse(readline(\"Was Imputation step already performed? Y/N :\")==\"Y\",RawLOD,as.numeric(readline(\"Enter your Cutoff LOD here:\")))  #Enter the LOD value as seen in the frequency plot\n",
    "temp_matrix <- c()\n",
    "for (i in 1:ncol(Samples)){ \n",
    "    \n",
    "    #Replacing the Sample intensities with Cutoff_LOD, if they are lower than Cutoff_LOD\n",
    "    x <- ifelse(Samples[,i] > Cutoff_LOD, Samples[,i],Cutoff_LOD)\n",
    "    temp_matrix <- cbind(temp_matrix,as.matrix(x))\n",
    "}\n",
    "colnames(temp_matrix) <- colnames(Samples)\n",
    "  \n",
    "Final_matrix <-c()\n",
    "for (i in 1:ncol(temp_matrix)){\n",
    "    \n",
    "     #Replacing the feature row with Cutoff_LOD if its Bg_bin value is 1, indicating it as noise, else retain the temporary dataset as such.\n",
    "    x <-ifelse(input_data1[,ncol(input_data1)] ==1, Cutoff_LOD, temp_matrix[,i])\n",
    "    Final_matrix <-cbind(Final_matrix,x)\n",
    "}\n",
    "colnames(Final_matrix) <- colnames(Samples)\n",
    "#write.csv(Final_matrix,file=paste0('Processed_Quant_Table_filled_with_Value_',Cutoff_LOD ,'.csv'),row.names =TRUE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720cdc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Final_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f428856",
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_matrix<-Final_matrix[rowMeans(Final_matrix)!= Cutoff_LOD,]  #removing all the rows with only cutoff values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a2dd7",
   "metadata": {},
   "source": [
    "## Normalization:\n",
    "The following code performs sample-centric (column-wise) normalisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a008a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (readline(\"Do you want to perform Normalization: Y/N:\") == 'Y'){\n",
    "    input_data <- Final_matrix\n",
    "    \n",
    "    #Getting column-wise sums of the input-data\n",
    "    sample_sum <- colSums(input_data, na.rm= TRUE, dims = 1)\n",
    "    \n",
    "    #Dividing each element of a particular column with its column sum\n",
    "    Normalized_data <- c()\n",
    "    for (i in 1:ncol(input_data)){\n",
    "        x <- input_data[,i] / sample_sum[i]\n",
    "        Normalized_data <- cbind(Normalized_data, x)\n",
    "    }\n",
    "    colnames(Normalized_data) <- names(sample_sum)\n",
    "\n",
    "} else return(Final_matrix)\n",
    "  \n",
    "print(paste('No.of NA values in Normalized data:',sum(is.na(Normalized_data)== TRUE)))\n",
    "#write.csv(Normalized_data,file='Normalised_Quant_table.csv',row.names =TRUE)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
